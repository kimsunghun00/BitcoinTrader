{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True, device='cpu'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        \"\"\"\n",
    "        gamma(int) : focusing parameter.\n",
    "        alpha(list) : alpha-balanced term.\n",
    "        size_average(bool) : whether to apply reduction to the output.\n",
    "        \"\"\"\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # input : N * C (btach_size, num_class)\n",
    "        # target : N (batch_size)\n",
    "\n",
    "        CE = F.cross_entropy(input, target, reduction='none')  # -log(pt)\n",
    "        pt = torch.exp(-CE)  # pt\n",
    "        loss = (1 - pt) ** self.gamma * CE  # -(1-pt)log(pt)\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            alpha = torch.tensor(self.alpha, dtype=torch.float).to(self.device)\n",
    "            # in case that a minority class is not selected when mini-batch sampling\n",
    "            if len(self.alpha) != len(torch.unique(target)):\n",
    "                temp = torch.zeros(len(self.alpha)).to(self.device)\n",
    "                temp[torch.unique(target)] = alpha.index_select(0, torch.unique(target))\n",
    "                alpha_t = temp.gather(0, target)\n",
    "                loss = alpha_t * loss\n",
    "            else:\n",
    "                alpha_t = alpha.gather(0, target)\n",
    "                loss = alpha_t * loss\n",
    "\n",
    "        if self.size_average:\n",
    "            loss = torch.mean(loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5150,  2.1537, -0.0139],\n",
      "        [-0.9463, -0.7248, -0.7565],\n",
      "        [ 0.6822, -1.5298, -2.2776],\n",
      "        [-0.1918, -0.6967, -2.9719],\n",
      "        [-1.5415,  0.9901, -0.9495],\n",
      "        [-2.1735,  1.7428,  0.5037],\n",
      "        [-1.9944, -0.8472, -0.7253],\n",
      "        [ 0.3618, -1.0586, -0.4950],\n",
      "        [ 1.7761,  1.1924,  1.1938],\n",
      "        [-1.4052,  0.8607, -0.4928]])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(10, 3)\n",
    "target = torch.tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1], dtype = torch.int64)\n",
    "\n",
    "print(input)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5195)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(input, target, reduction = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5195)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FL = FocalLoss(gamma = 0, size_average = True)\n",
    "FL(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8151)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FL = FocalLoss(gamma = 5, size_average = True)\n",
    "FL(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1557)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FL = FocalLoss(gamma = 5, alpha = [0.1, 0.7, 0.2], size_average = True)\n",
    "FL(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.18573670e-01, -1.09015152e+00, -2.69082212e+00, ...,\n",
       "         -1.49333926e+00,  1.12770970e+00, -1.98849061e+00],\n",
       "        [ 1.71868894e+00,  1.01534847e+00,  1.62848327e+00, ...,\n",
       "          5.12436603e-02, -2.01925104e+00,  8.94938775e-01],\n",
       "        [-7.76215994e-01, -5.26727243e-01,  2.38813286e+00, ...,\n",
       "         -1.18040853e+00, -5.18561601e-01, -6.07886523e-01],\n",
       "        ...,\n",
       "        [ 1.92206385e-01, -1.81492593e+00, -1.20385230e+00, ...,\n",
       "          9.19349556e-01, -2.98661244e-01, -1.95589469e+00],\n",
       "        [ 1.65530608e+00,  1.17063079e+00, -2.39808291e+00, ...,\n",
       "          1.34965446e+00,  1.25916186e+00, -6.06356318e-02],\n",
       "        [-2.74208401e+00,  4.73398204e-02, -1.97775115e+00, ...,\n",
       "          7.38647522e-01, -6.01786625e-01,  1.32696211e+00]],\n",
       "\n",
       "       [[ 4.71637191e-01,  2.27699562e-01,  9.46043829e-01, ...,\n",
       "          6.91935757e-01,  1.98037802e+00, -9.97883123e-01],\n",
       "        [ 3.08345832e-01,  1.35438811e+00,  1.54770231e-01, ...,\n",
       "         -8.72665473e-01,  5.12519885e-01,  4.75422807e-01],\n",
       "        [ 1.91682885e+00,  8.62215027e-01,  1.96153500e+00, ...,\n",
       "          8.45098075e-01, -2.96267179e-01, -1.99647022e+00],\n",
       "        ...,\n",
       "        [-1.63661305e+00,  7.66375093e-01,  1.67555292e-01, ...,\n",
       "         -4.22995924e-01, -8.98792653e-01, -9.62300705e-01],\n",
       "        [-7.52925180e-01,  2.16277953e+00, -1.77180392e-01, ...,\n",
       "         -5.08062736e-01, -6.62885971e-01, -2.01802349e+00],\n",
       "        [ 1.03029789e+00,  1.05874580e-03, -5.10125983e-01, ...,\n",
       "          1.80316292e+00,  1.94726764e+00, -5.62943685e-01]],\n",
       "\n",
       "       [[ 9.70786451e-01, -4.95111714e-01,  1.16925578e-01, ...,\n",
       "         -6.39066662e-01, -1.26715451e+00, -9.40313367e-01],\n",
       "        [-1.41156082e+00, -1.12912834e+00, -1.01010901e+00, ...,\n",
       "          6.62175312e-01, -1.13746611e+00,  7.49836925e-02],\n",
       "        [ 4.09664715e-01, -4.59550967e-01, -3.58027446e-01, ...,\n",
       "          9.92232705e-02, -1.56281898e+00,  4.09788917e-01],\n",
       "        ...,\n",
       "        [-1.10284808e+00,  2.35364839e-01, -1.55171836e-01, ...,\n",
       "         -1.49662419e+00, -5.98373804e-03, -7.56450197e-01],\n",
       "        [-7.32685124e-02, -6.85721765e-02, -4.35045449e-01, ...,\n",
       "         -8.63624387e-02, -3.96968126e-01,  2.41406435e+00],\n",
       "        [-1.35903275e+00,  1.18969832e+00, -1.51960628e+00, ...,\n",
       "         -3.69771597e-01, -7.83853724e-01, -4.84997098e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.36473654e+00, -7.21328360e-01, -8.55099184e-01, ...,\n",
       "          2.42157325e+00, -2.94229358e-01, -4.07721589e-03],\n",
       "        [-3.52573520e-01, -7.92876025e-01, -1.52454707e-01, ...,\n",
       "          5.34732483e-01, -2.41398187e-01, -4.07530501e-01],\n",
       "        [-1.43755497e+00,  2.89278738e-01, -1.37757027e-01, ...,\n",
       "         -7.45770781e-01, -2.90196715e-01, -1.44394421e+00],\n",
       "        ...,\n",
       "        [-2.15804637e+00, -8.86761121e-01, -1.06790496e+00, ...,\n",
       "         -1.01052753e+00, -1.38622189e+00,  9.13564046e-01],\n",
       "        [-4.15196695e-01, -8.76308224e-01, -4.50699238e-01, ...,\n",
       "         -6.56928281e-01, -1.41512900e-01,  1.13717262e+00],\n",
       "        [-3.02889967e-01, -1.10925147e+00, -3.38778365e-01, ...,\n",
       "         -9.36800148e-03, -6.91656358e-01,  5.00775954e-01]],\n",
       "\n",
       "       [[ 1.12417431e+00,  1.37279941e+00, -2.44263110e-01, ...,\n",
       "         -2.73525805e-01, -1.99977417e+00, -6.04511964e-01],\n",
       "        [-3.74452242e-01, -4.69559635e-01,  8.38760413e-01, ...,\n",
       "         -1.11310264e+00,  4.56575862e-01,  1.29702489e+00],\n",
       "        [ 6.23330562e-01,  1.69226203e+00, -1.30132004e-01, ...,\n",
       "          9.10884622e-01, -2.74841867e-01, -1.25013967e+00],\n",
       "        ...,\n",
       "        [ 1.09084664e+00, -1.14016788e+00,  7.83435765e-01, ...,\n",
       "          1.83502271e+00,  2.50007843e-01,  1.09534947e-01],\n",
       "        [-1.85481209e+00,  1.01779916e+00, -4.33007661e-01, ...,\n",
       "          1.40565564e+00, -1.20665578e+00, -2.29663204e-02],\n",
       "        [-9.38745504e-01,  9.13500851e-01, -1.44985877e-01, ...,\n",
       "          1.08291457e-01, -4.38970494e-02,  9.14515185e-01]],\n",
       "\n",
       "       [[ 9.86955010e-01,  1.75533873e+00,  1.83086701e+00, ...,\n",
       "          6.65046089e-02, -7.89667908e-01, -6.01947627e-01],\n",
       "        [ 8.13207403e-01, -9.96651783e-02, -5.55006002e-01, ...,\n",
       "         -2.81890896e+00, -1.15361048e+00,  1.75269154e+00],\n",
       "        [ 4.94320079e-01,  3.91623418e-02, -6.61670287e-01, ...,\n",
       "         -8.86334523e-01, -2.78006047e-01, -3.32975682e-01],\n",
       "        ...,\n",
       "        [ 1.01918674e+00, -1.27573407e+00,  1.67283149e+00, ...,\n",
       "          1.51890520e+00, -9.09204558e-01,  3.27096701e-01],\n",
       "        [-5.79350206e-01, -5.63985750e-01, -4.20907623e-01, ...,\n",
       "         -1.66180136e-01,  8.72363669e-02,  8.22330541e-01],\n",
       "        [ 9.99045030e-01,  1.44263335e-01,  2.14522278e-01, ...,\n",
       "         -2.13809101e+00, -2.03283097e+00,  1.79027257e-01]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.random.randn(99, 15, 17)\n",
    "np.concatenate([arr, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3., inf,  4.,  5.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_idx = np.where(np.isnan(arr))[0]\n",
    "print(nan_idx)\n",
    "arr = np.delete(arr, nan_idx)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_idx = np.where(np.isinf(arr))[0]\n",
    "print(inf_idx)\n",
    "arr = np.delete(arr, inf_idx)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., nan, inf, 4., 5.], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = torch.tensor(arr)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing invalid inputs..\n"
     ]
    }
   ],
   "source": [
    "print('removing invalid inputs..')\n",
    "invalid_input_list = []\n",
    "for i in range(len(arr)):\n",
    "    x = arr[i]\n",
    "    if torch.isinf(x).sum() > 0 or torch.isnan(x).sum() > 0:\n",
    "        invalid_input_list.append(i)\n",
    "\n",
    "valid_input_list = list(range(len(arr)))\n",
    "for e in invalid_input_list:\n",
    "    valid_input_list.remove(e)\n",
    "train_features = arr[valid_input_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5.], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn import functional as F\n",
    "import tqdm\n",
    "\n",
    "from dataset import Dataset\n",
    "ds = Dataset(file_path='./data', window_size = 15, test_size = 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [01:13<00:00, 12.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KRW-BCH', 'KRW-BTC', 'KRW-EOS', 'KRW-ETC', 'KRW-ETH', 'KRW-NEO'] are combined as training set\n",
      "removing invalid inputs..\n",
      "[]\n",
      "completed\n",
      "torch.Size([926504, 15, 17]) torch.Size([926504])\n",
      "torch.Size([49985, 15, 17]) torch.Size([49985])\n"
     ]
    }
   ],
   "source": [
    "(train_features, train_labels), (test_features, test_labels) = ds.get_dataset()\n",
    "print(train_features.shape, train_labels.shape)\n",
    "print(test_features.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
