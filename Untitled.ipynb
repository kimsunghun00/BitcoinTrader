{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Dataset\n",
    "\n",
    "ds = Dataset(file_path='./data', window_size = 30, test_size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KRW-BCH', 'KRW-BTC', 'KRW-BTG', 'KRW-DOT', 'KRW-ENJ', 'KRW-EOS', 'KRW-ETC', 'KRW-ETH', 'KRW-LOOM', 'KRW-LTC', 'KRW-MBL', 'KRW-MED', 'KRW-MLK', 'KRW-STMX'] are combined as training set\n"
     ]
    }
   ],
   "source": [
    "(train_features, train_labels), (test_features, test_labels) = ds.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58662, 30, 17) (58662, 3)\n",
      "(2970, 30, 17) (2970, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, train_labels.shape)\n",
    "print(test_features.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras를 활용한 LSTM 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 12341118051805763404]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 30, 17)]          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 30, 512)           561152    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               1574912   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "signal (Dense)               (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 3,714,051\n",
      "Trainable params: 3,714,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input = Input(shape = (train_features.shape[1], train_features.shape[2]), name = 'input')\n",
    "x = layers.Bidirectional(layers.LSTM(256, return_sequences = True, recurrent_dropout = 0.1))(input)\n",
    "x = layers.Bidirectional(layers.LSTM(256, return_sequences = False, recurrent_dropout = 0.1, dropout = 0.3))(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "output = layers.Dense(3, activation = 'softmax', name = 'signal')(x)\n",
    "\n",
    "model = Model(input, output)\n",
    "model.build((None, train_features.shape[1], train_features.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "learning_rate = 0.001\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate = learning_rate),\n",
    "              loss = 'categorical_crossentropy', metrics = 'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "161/161 [==============================] - 442s 3s/step - loss: 0.7841 - acc: 0.6029 - val_loss: 0.6444 - val_acc: 0.6755\n",
      "Epoch 2/100\n",
      "161/161 [==============================] - 535s 3s/step - loss: 0.5835 - acc: 0.7229 - val_loss: 0.5204 - val_acc: 0.7475\n",
      "Epoch 3/100\n",
      "161/161 [==============================] - 563s 4s/step - loss: 0.5332 - acc: 0.7472 - val_loss: 0.5298 - val_acc: 0.7378\n",
      "Epoch 4/100\n",
      "161/161 [==============================] - 575s 4s/step - loss: 0.5133 - acc: 0.7609 - val_loss: 0.5420 - val_acc: 0.7248\n",
      "Epoch 5/100\n",
      "161/161 [==============================] - 582s 4s/step - loss: 0.4983 - acc: 0.7653 - val_loss: 0.4909 - val_acc: 0.7618\n",
      "Epoch 6/100\n",
      "161/161 [==============================] - 589s 4s/step - loss: 0.4925 - acc: 0.7690 - val_loss: 0.4855 - val_acc: 0.7637\n",
      "Epoch 7/100\n",
      "161/161 [==============================] - 594s 4s/step - loss: 0.4805 - acc: 0.7743 - val_loss: 0.4804 - val_acc: 0.7673\n",
      "Epoch 8/100\n",
      "161/161 [==============================] - 594s 4s/step - loss: 0.4709 - acc: 0.7801 - val_loss: 0.4851 - val_acc: 0.7623\n",
      "Epoch 9/100\n",
      "161/161 [==============================] - 596s 4s/step - loss: 0.4716 - acc: 0.7786 - val_loss: 0.4735 - val_acc: 0.7716\n",
      "Epoch 10/100\n",
      "161/161 [==============================] - 596s 4s/step - loss: 0.4593 - acc: 0.7853 - val_loss: 0.4522 - val_acc: 0.7812\n",
      "Epoch 11/100\n",
      "161/161 [==============================] - 594s 4s/step - loss: 0.4530 - acc: 0.7879 - val_loss: 0.4796 - val_acc: 0.7691\n",
      "Epoch 12/100\n",
      "161/161 [==============================] - 595s 4s/step - loss: 0.4542 - acc: 0.7882 - val_loss: 0.4583 - val_acc: 0.7792\n",
      "Epoch 13/100\n",
      "161/161 [==============================] - 597s 4s/step - loss: 0.4485 - acc: 0.7915 - val_loss: 0.4495 - val_acc: 0.7810\n",
      "Epoch 14/100\n",
      "161/161 [==============================] - 596s 4s/step - loss: 0.4387 - acc: 0.7970 - val_loss: 0.4486 - val_acc: 0.7843\n",
      "Epoch 15/100\n",
      "161/161 [==============================] - 596s 4s/step - loss: 0.4379 - acc: 0.7955 - val_loss: 0.4462 - val_acc: 0.7849\n",
      "Epoch 16/100\n",
      "161/161 [==============================] - 597s 4s/step - loss: 0.4308 - acc: 0.8011 - val_loss: 0.4559 - val_acc: 0.7842\n",
      "Epoch 17/100\n",
      "161/161 [==============================] - 597s 4s/step - loss: 0.4308 - acc: 0.8006 - val_loss: 0.4449 - val_acc: 0.7889\n",
      "Epoch 18/100\n",
      "161/161 [==============================] - 599s 4s/step - loss: 0.4241 - acc: 0.8031 - val_loss: 0.4369 - val_acc: 0.7915\n",
      "Epoch 19/100\n",
      "161/161 [==============================] - 598s 4s/step - loss: 0.4260 - acc: 0.8032 - val_loss: 0.4411 - val_acc: 0.7927\n",
      "Epoch 20/100\n",
      "161/161 [==============================] - 600s 4s/step - loss: 0.4214 - acc: 0.8059 - val_loss: 0.4450 - val_acc: 0.7848\n",
      "Epoch 21/100\n",
      "161/161 [==============================] - 599s 4s/step - loss: 0.4131 - acc: 0.8080 - val_loss: 0.4398 - val_acc: 0.7915\n",
      "Epoch 22/100\n",
      "161/161 [==============================] - 598s 4s/step - loss: 0.4103 - acc: 0.8080 - val_loss: 0.4623 - val_acc: 0.7831\n",
      "Epoch 23/100\n",
      "161/161 [==============================] - 598s 4s/step - loss: 0.4056 - acc: 0.8110 - val_loss: 0.4556 - val_acc: 0.7867\n",
      "Epoch 24/100\n",
      "161/161 [==============================] - 598s 4s/step - loss: 0.4049 - acc: 0.8115 - val_loss: 0.4514 - val_acc: 0.7871\n",
      "Epoch 25/100\n",
      "161/161 [==============================] - 594s 4s/step - loss: 0.3995 - acc: 0.8146 - val_loss: 0.4531 - val_acc: 0.7886\n",
      "Epoch 26/100\n",
      "161/161 [==============================] - 595s 4s/step - loss: 0.3896 - acc: 0.8187 - val_loss: 0.4654 - val_acc: 0.7857\n",
      "Epoch 27/100\n",
      "161/161 [==============================] - 595s 4s/step - loss: 0.3848 - acc: 0.8236 - val_loss: 0.4636 - val_acc: 0.7883\n",
      "Epoch 28/100\n",
      "161/161 [==============================] - 593s 4s/step - loss: 0.3766 - acc: 0.8302 - val_loss: 0.4864 - val_acc: 0.7837\n",
      "Epoch 29/100\n",
      "161/161 [==============================] - 592s 4s/step - loss: 0.3663 - acc: 0.8305 - val_loss: 0.4815 - val_acc: 0.7870\n",
      "Epoch 30/100\n",
      "161/161 [==============================] - 593s 4s/step - loss: 0.3649 - acc: 0.8332 - val_loss: 0.4742 - val_acc: 0.7869\n",
      "Epoch 31/100\n",
      "161/161 [==============================] - 592s 4s/step - loss: 0.3499 - acc: 0.8384 - val_loss: 0.5290 - val_acc: 0.7670\n",
      "Epoch 32/100\n",
      "161/161 [==============================] - 595s 4s/step - loss: 0.3410 - acc: 0.8445 - val_loss: 0.5136 - val_acc: 0.7783\n",
      "Epoch 33/100\n",
      "161/161 [==============================] - 594s 4s/step - loss: 0.3266 - acc: 0.8539 - val_loss: 0.5524 - val_acc: 0.7661\n",
      "Epoch 34/100\n",
      "161/161 [==============================] - 594s 4s/step - loss: 0.3110 - acc: 0.8599 - val_loss: 0.5571 - val_acc: 0.7741\n",
      "Epoch 35/100\n",
      "161/161 [==============================] - 593s 4s/step - loss: 0.3014 - acc: 0.8674 - val_loss: 0.5823 - val_acc: 0.7690\n",
      "Epoch 36/100\n",
      "161/161 [==============================] - 594s 4s/step - loss: 0.2859 - acc: 0.8710 - val_loss: 0.6016 - val_acc: 0.7685\n",
      "Epoch 37/100\n",
      "161/161 [==============================] - 592s 4s/step - loss: 0.2740 - acc: 0.8812 - val_loss: 0.6633 - val_acc: 0.7747\n",
      "Epoch 38/100\n",
      "161/161 [==============================] - 594s 4s/step - loss: 0.2521 - acc: 0.8926 - val_loss: 0.6924 - val_acc: 0.7640\n",
      "Epoch 39/100\n",
      "161/161 [==============================] - 593s 4s/step - loss: 0.2395 - acc: 0.8986 - val_loss: 0.6910 - val_acc: 0.7585\n",
      "Epoch 40/100\n",
      "161/161 [==============================] - 593s 4s/step - loss: 0.2248 - acc: 0.9034 - val_loss: 0.7632 - val_acc: 0.7671\n",
      "Epoch 41/100\n",
      "161/161 [==============================] - 592s 4s/step - loss: 0.2017 - acc: 0.9145 - val_loss: 0.8039 - val_acc: 0.7648\n",
      "Epoch 42/100\n",
      "161/161 [==============================] - 592s 4s/step - loss: 0.1904 - acc: 0.9209 - val_loss: 0.8315 - val_acc: 0.7585\n",
      "Epoch 43/100\n",
      "161/161 [==============================] - 593s 4s/step - loss: 0.1747 - acc: 0.9278 - val_loss: 0.8803 - val_acc: 0.7599\n",
      "Epoch 44/100\n",
      "161/161 [==============================] - 593s 4s/step - loss: 0.1563 - acc: 0.9360 - val_loss: 0.9097 - val_acc: 0.7598\n",
      "Epoch 45/100\n",
      "161/161 [==============================] - 592s 4s/step - loss: 0.1411 - acc: 0.9428 - val_loss: 0.9373 - val_acc: 0.7592\n",
      "Epoch 46/100\n",
      "161/161 [==============================] - 593s 4s/step - loss: 0.1334 - acc: 0.9446 - val_loss: 1.0410 - val_acc: 0.7574\n",
      "Epoch 47/100\n",
      "161/161 [==============================] - 591s 4s/step - loss: 0.1240 - acc: 0.9519 - val_loss: 0.9861 - val_acc: 0.7488\n",
      "Epoch 48/100\n",
      "161/161 [==============================] - 593s 4s/step - loss: 0.1068 - acc: 0.9578 - val_loss: 1.1334 - val_acc: 0.7555\n",
      "Epoch 49/100\n",
      "161/161 [==============================] - 593s 4s/step - loss: 0.1033 - acc: 0.9599 - val_loss: 1.0792 - val_acc: 0.7510\n",
      "Epoch 50/100\n",
      "161/161 [==============================] - 592s 4s/step - loss: 0.0883 - acc: 0.9658 - val_loss: 1.1844 - val_acc: 0.7522\n",
      "Epoch 51/100\n",
      "161/161 [==============================] - 591s 4s/step - loss: 0.0892 - acc: 0.9658 - val_loss: 1.2174 - val_acc: 0.7488\n",
      "Epoch 52/100\n",
      "161/161 [==============================] - 594s 4s/step - loss: 0.0881 - acc: 0.9662 - val_loss: 1.2161 - val_acc: 0.7535\n",
      "Epoch 53/100\n",
      "161/161 [==============================] - 592s 4s/step - loss: 0.0706 - acc: 0.9736 - val_loss: 1.2086 - val_acc: 0.7534\n",
      "Epoch 54/100\n",
      "161/161 [==============================] - 589s 4s/step - loss: 0.0701 - acc: 0.9751 - val_loss: 1.3794 - val_acc: 0.7587\n",
      "Epoch 55/100\n",
      "161/161 [==============================] - 590s 4s/step - loss: 0.0690 - acc: 0.9758 - val_loss: 1.3277 - val_acc: 0.7532\n",
      "Epoch 56/100\n",
      "161/161 [==============================] - 592s 4s/step - loss: 0.0637 - acc: 0.9757 - val_loss: 1.3210 - val_acc: 0.7596\n",
      "Epoch 57/100\n",
      " 70/161 [============>.................] - ETA: 5:07 - loss: 0.0558 - acc: 0.9811"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-90991d7433fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                     shuffle=True, verbose = 1)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kimsunghun\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kimsunghun\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kimsunghun\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kimsunghun\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kimsunghun\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kimsunghun\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\kimsunghun\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs = 30, batch_size = 256,\n",
    "                    validation_split = 0.3,\n",
    "                    shuffle=True, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3eaf3050801b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, label = 'Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.4.1-cp37-cp37m-win_amd64.whl (7.1 MB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\kimsunghun\\anaconda3\\envs\\tensorflow2\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.2.0-cp37-cp37m-win_amd64.whl (2.2 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\kimsunghun\\anaconda3\\envs\\tensorflow2\\lib\\site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kimsunghun\\anaconda3\\envs\\tensorflow2\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp37-cp37m-win_amd64.whl (51 kB)\n",
      "Requirement already satisfied: six in c:\\users\\kimsunghun\\anaconda3\\envs\\tensorflow2\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Installing collected packages: pillow, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.4.1 pillow-8.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
